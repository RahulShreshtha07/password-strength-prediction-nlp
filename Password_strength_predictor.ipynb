{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e82bf1-899c-4720-85f6-9332201c43ff",
   "metadata": {},
   "source": [
    "# Password Strength Prediction using Machine Learning & NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c3c15-f0e7-4771-8d6c-377f91af6490",
   "metadata": {},
   "source": [
    "\n",
    "### Objective\n",
    "The objective of this project is to build a machine learning system that predicts the strength of a password using character-level NLP techniques and security-inspired engineered features. The model classifies passwords into multiple strength levels ranging from *Very Weak* to *Very Strong*, with a focus on identifying weak and risky passwords accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3c295-52de-4b10-8da2-3098adefb75f",
   "metadata": {},
   "source": [
    "### Business / Security Problem\n",
    "Weak and predictable passwords are a major cause of security breaches and account compromise. Many existing password strength meters rely on simple heuristics such as minimum length or the presence of symbols, which often fail to reflect real-world password patterns.\n",
    "\n",
    "This project addresses the problem of **automated password strength estimation** by learning patterns from large-scale real-world password data. The goal is not to crack passwords, but to assess their relative strength and highlight risky choices in a responsible and ethical manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54985303-86c7-42cb-bf8c-4488aaebe43d",
   "metadata": {},
   "source": [
    "### Problem Type\n",
    "- Supervised Machine Learning  \n",
    "- Multi-class Classification  \n",
    "- Input: Raw password strings  \n",
    "- Output: Password strength category  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac9941-7418-40c4-a2a5-465a2b7a9bf8",
   "metadata": {},
   "source": [
    "### Strength Classes\n",
    "The password strength prediction task is formulated as a multi-class classification problem with the following categories:\n",
    "\n",
    "- Very Weak  \n",
    "- Weak  \n",
    "- Medium  \n",
    "- Strong  \n",
    "- Very Strong  \n",
    "\n",
    "This setup provides finer granularity compared to binary or three-class systems and better reflects real-world password quality differences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dc862f-8f88-4a6f-a35a-b219e53d34cf",
   "metadata": {},
   "source": [
    "### Datasets Used\n",
    "\n",
    "#### Primary Dataset (Main Project Dataset)\n",
    "**PWLDS â€“ Password Weakness and Level Dataset**\n",
    "\n",
    "- Large-scale dataset containing real-world passwords\n",
    "- Used for:\n",
    "  - Feature engineering\n",
    "  - Model training and evaluation\n",
    "  - Error analysis\n",
    "  - Final conclusions\n",
    "\n",
    "#### Secondary Dataset (Baseline Comparison Only)\n",
    "**Password Strength Classifier Dataset (Kaggle)**\n",
    "\n",
    "- Smaller, lower-granularity dataset\n",
    "- Used only for:\n",
    "  - Training a simple baseline model\n",
    "  - External comparison\n",
    "  - Strengthening evaluation credibility\n",
    "\n",
    "> The secondary dataset is not used for feature design, hyperparameter tuning, or final model conclusions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab9411-2d8c-409f-a678-78596b43bae8",
   "metadata": {},
   "source": [
    "### Evaluation Focus\n",
    "Model evaluation emphasizes:\n",
    "- Overall performance using macro F1-score\n",
    "- Recall on **Very Weak** and **Weak** password classes, as misclassifying weak passwords as strong has higher security risk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a0647b-8057-4d72-b746-01409aab69b0",
   "metadata": {},
   "source": [
    "### Ethical & Responsible Use\n",
    "This project uses publicly available leaked-password datasets strictly for educational and analytical purposes. No real user-entered passwords are collected, logged, or stored. The resulting models are intended for research and learning, not for real-world password validation systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f47ea-2a50-4822-b69a-56b6f80e6779",
   "metadata": {},
   "source": [
    "### Project Scope & Limitations\n",
    "- The model estimates relative password strength, not exact cracking time\n",
    "- It does not simulate real password attacks\n",
    "- Results are dataset-dependent and may not generalize to all user populations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a4944-0191-43dc-957f-d713c44eecc5",
   "metadata": {},
   "source": [
    "## Notebook Roadmap\n",
    "The notebook is organized into clearly defined phases:\n",
    "\n",
    "- Phase 1: Data Loading & Understanding  \n",
    "- Phase 2: Feature Engineering  \n",
    "- Phase 3: Baselines & Ablation Study  \n",
    "- Phase 4: Tree-Based Models  \n",
    "- Phase 5: Neural Network Model  \n",
    "- Phase 6: External Baseline Comparison  \n",
    "- Phase 7: Security Interpretation & Research Context  \n",
    "- Phase 8: Final Results & Conclusions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e310c1c-c717-4fbf-8c95-c3a5194770c3",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# Phase 1: Data Loading & Understanding\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267821a2-a819-4ff1-a381-022a6ce6d79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Password</th>\n",
       "      <th>Strength_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7hqwv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cjml</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asuy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kcyth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whcq</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Password  Strength_Level\n",
       "0    7hqwv               0\n",
       "1     cjml               0\n",
       "2     asuy               0\n",
       "3    kcyth               0\n",
       "4     whcq               0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load only required columns to keep memory usage under control\n",
    "pwlds = pd.read_csv(\"pwlds_full.csv\")\n",
    "\n",
    "pwlds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0110995-7c70-40aa-b9d7-989fe8215dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7hqwv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cjml</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asuy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kcyth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whcq</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  password  strength\n",
       "0    7hqwv         0\n",
       "1     cjml         0\n",
       "2     asuy         0\n",
       "3    kcyth         0\n",
       "4     whcq         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize column names\n",
    "pwlds = pwlds.rename(columns={\n",
    "    \"Password\": \"password\",\n",
    "    \"Strength_Level\": \"strength\"\n",
    "})\n",
    "\n",
    "pwlds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bddcba48-b1c0-4a04-b669-31cd0e6d5ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000470, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwlds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cc80ee6-2157-405f-9fad-8d5af4e8b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000470 entries, 0 to 10000469\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   password  object\n",
      " 1   strength  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 152.6+ MB\n"
     ]
    }
   ],
   "source": [
    "pwlds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce446b00-18b8-4517-a92a-0d41c840fa66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password    4\n",
       "strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "pwlds.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40767afb-3a82-439a-980a-fe418ed804d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password    0\n",
       "strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwlds = pwlds.dropna(subset=[\"password\"])\n",
    "pwlds.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706007a4-3e93-48cb-a81f-a08c0b76adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Strength Level Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220766dc-35f9-4e9a-b683-529f52884525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strength\n",
       "3    2000382\n",
       "0    2000039\n",
       "2    2000024\n",
       "1    2000021\n",
       "4    2000000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwlds[\"strength\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d770c2-ae6e-4c2b-9dfa-159bad927c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Password Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014c99fb-937e-4971-b57b-780f70e5c858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       10000466\n",
       "unique       8635302\n",
       "top       abolisherL\n",
       "freq               4\n",
       "Name: password, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute password length\n",
    "pwlds[\"password_length\"] = pwlds[\"password\"].str.len()\n",
    "\n",
    "pwlds[\"password\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca510850-e1b8-4458-8549-584ca8757488",
   "metadata": {},
   "source": [
    "## Phase 1 Checkpoint\n",
    "\n",
    "At this stage, we have:\n",
    "- Successfully loaded a large-scale password dataset\n",
    "- Understood dataset size and schema\n",
    "- Identified class distribution and potential imbalance\n",
    "- Observed basic password characteristics\n",
    "\n",
    "In the next phase, we will focus on transforming raw passwords into\n",
    "meaningful numerical features for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f7fe9-b450-41d2-aba4-c061b48f94f1",
   "metadata": {},
   "source": [
    "### Duplicate Password Analysis\n",
    "\n",
    "Real-world password datasets often contain duplicate passwords because\n",
    "many users choose the same or similar passwords. Before modeling, we\n",
    "analyze duplicate password occurrences and decide how to handle them.\n",
    "\n",
    "At this stage, we focus only on understanding duplicates, not removing\n",
    "them prematurely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cadea348-4478-45f6-9410-be7bda6d97b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000466, 8635302, 1365164)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count duplicate password entries\n",
    "total_rows = len(pwlds)\n",
    "unique_passwords = pwlds[\"password\"].nunique()\n",
    "\n",
    "total_rows, unique_passwords, total_rows - unique_passwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7770d7e5-763c-413d-9a7c-d2288d7b3f80",
   "metadata": {},
   "source": [
    "### Duplicate Passwords with Conflicting Labels\n",
    "\n",
    "A critical check is whether the same password appears with different\n",
    "strength labels. If this happens, we must resolve label inconsistency\n",
    "before modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a3df27d-7771-49db-99e0-194b78012951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password\n",
       "acerbityT|    2\n",
       "abrogator^    2\n",
       "Achyrodesl    2\n",
       "abrogator[    2\n",
       "acentrouso    2\n",
       "Name: strength, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the same password appears with multiple strength labels\n",
    "label_variation = (\n",
    "    pwlds.groupby(\"password\")[\"strength\"]\n",
    "    .nunique()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "label_variation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb0e7225-a266-4792-9ef9-0286b7de4d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37095"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of passwords mapped to more than one strength class\n",
    "(label_variation > 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db925ef-cbc5-44da-aa0f-c207c8b4418c",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "- Duplicate passwords are expected in real-world datasets and reflect\n",
    "  common user behavior.\n",
    "- If a password appears with multiple strength labels, this indicates\n",
    "  label noise or ambiguity.\n",
    "- We will decide how to handle such cases explicitly before modeling\n",
    "  to avoid confusing the learning algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577dc194-68a6-4afd-a71c-3f2b3a76da62",
   "metadata": {},
   "source": [
    "### Decision on Duplicate Passwords\n",
    "\n",
    "- Duplicate passwords with the **same strength label** are retained, as\n",
    "  they reflect real-world frequency information.\n",
    "- Passwords that appear with **conflicting strength labels** introduce\n",
    "  ambiguity and will be handled carefully in the next step.\n",
    "\n",
    "The final decision (retain, deduplicate, or resolve conflicts) will be\n",
    "made explicitly and documented before feature engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda59535-9cdb-4ded-ad56-9cd7f6692087",
   "metadata": {},
   "source": [
    "### Resolving Duplicate Passwords with Conflicting Labels\n",
    "\n",
    "Some passwords may appear multiple times in the dataset with different\n",
    "strength labels. This introduces label ambiguity, which can negatively\n",
    "affect supervised learning models.\n",
    "\n",
    "To ensure label consistency, we explicitly identify and handle such cases\n",
    "before proceeding to feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df2c298-2acf-44c7-834b-b43c7e99f8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37095"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify passwords that map to more than one strength label\n",
    "conflicting_passwords = (\n",
    "    pwlds.groupby(\"password\")[\"strength\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"label_count\")\n",
    ")\n",
    "\n",
    "conflicting_passwords = conflicting_passwords[\n",
    "    conflicting_passwords[\"label_count\"] > 1\n",
    "]\n",
    "\n",
    "len(conflicting_passwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5509d7b2-b294-4701-8507-3c0afaa33ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000466, 9889407, 111059)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store row count before cleaning\n",
    "rows_before = len(pwlds)\n",
    "\n",
    "# Remove passwords with conflicting strength labels\n",
    "pwlds = pwlds[~pwlds[\"password\"].isin(conflicting_passwords[\"password\"])]\n",
    "\n",
    "rows_after = len(pwlds)\n",
    "\n",
    "rows_before, rows_after, rows_before - rows_after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba63283-8b1b-43ce-9463-11a1a27e66a6",
   "metadata": {},
   "source": [
    "### Post-Cleaning Validation\n",
    "\n",
    "After resolving duplicate label conflicts, we verify that:\n",
    "- Each password maps to exactly one strength label\n",
    "- No missing values remain in critical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dc6c1d3-85c8-49f1-8e8f-7036009359e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm no password maps to multiple strength labels\n",
    "pwlds.groupby(\"password\")[\"strength\"].nunique().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffb717df-ad51-4ff9-b681-e9b9cd967ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password           0\n",
       "strength           0\n",
       "password_length    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final missing value check\n",
    "pwlds.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2b737-20b6-4fb3-8f20-b0d4434f0fcc",
   "metadata": {},
   "source": [
    "### Phase 1 Summary\n",
    "\n",
    "In this phase, we:\n",
    "- Loaded a large-scale real-world password dataset\n",
    "- Standardized column names\n",
    "- Removed records with missing passwords\n",
    "- Analyzed and handled duplicate passwords\n",
    "- Eliminated label ambiguity to ensure clean supervision\n",
    "\n",
    "The dataset is now consistent and ready for feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda17ba-9172-4aa7-8e2e-14597cac8ff9",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "# Phase 2: Feature Engineering & Feature-Level EDA\n",
    "# ===============================\n",
    "\n",
    "## Purpose\n",
    "Transform raw password strings into meaningful numerical features that\n",
    "capture structural complexity, character composition, and information\n",
    "content relevant to password strength.\n",
    "\n",
    "## What We Do\n",
    "- Ensure raw password data remains intact\n",
    "- Engineer structured security features\n",
    "- Add an information-theoretic entropy feature\n",
    "- Generate character-level NLP features using TF-IDF (memory-safe)\n",
    "\n",
    "## Expected Output\n",
    "- Clean, interpretable engineered features\n",
    "- Scalable NLP feature representation\n",
    "- Feature sets ready for modeling and ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70007eb5-c914-430b-a4e9-704720f8e744",
   "metadata": {},
   "source": [
    "## 2.0 Ensure Correct Data Type for Passwords\n",
    "\n",
    "Before applying string-based feature engineering, we explicitly cast the\n",
    "password column to string type to avoid issues caused by mixed or inferred\n",
    "data types in large CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "592ae078-1627-49c7-9af8-3b53a6689389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure passwords are treated as strings (do NOT overwrite the column later)\n",
    "pwlds[\"password\"] = pwlds[\"password\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b500a-d948-41f5-b885-04316b251ad1",
   "metadata": {},
   "source": [
    "### Remove Invalid Password Artifacts\n",
    "\n",
    "After enforcing string type, some invalid artifacts (e.g., 'nan', 'None',\n",
    "or extremely short values) may exist due to casting. These entries do not\n",
    "represent real passwords and are removed before feature computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dac25d7-7daf-43e4-9f61-20cf7e0d3c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9889333, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove invalid password artifacts introduced by string casting\n",
    "pwlds = pwlds[pwlds[\"password\"].str.len() > 1]\n",
    "pwlds = pwlds[~pwlds[\"password\"].isin([\"nan\", \"None\", \"null\"])]\n",
    "\n",
    "pwlds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6fe3f-48f8-41bd-9765-80067d334d3d",
   "metadata": {},
   "source": [
    "### Structured Security Features\n",
    "\n",
    "We engineer interpretable, security-inspired features that capture\n",
    "basic password characteristics such as length, character composition,\n",
    "and repetition patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fa7b19e-c618-4dde-a574-2b0d6bb00500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05ec81ec-cbb3-496e-a626-6886e2f6e763",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwlds[\"password_length\"] = pwlds[\"password\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b89432d1-26d2-43c2-b8de-dcf7d53749ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count different character types\n",
    "pwlds[\"upper_count\"] = pwlds[\"password\"].str.count(r\"[A-Z]\")\n",
    "pwlds[\"lower_count\"] = pwlds[\"password\"].str.count(r\"[a-z]\")\n",
    "pwlds[\"digit_count\"] = pwlds[\"password\"].str.count(r\"[0-9]\")\n",
    "pwlds[\"symbol_count\"] = pwlds[\"password\"].str.count(r\"[^A-Za-z0-9]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f56abd-1883-4727-81f7-6a21cee34af5",
   "metadata": {},
   "source": [
    "### Character Ratios\n",
    "\n",
    "Raw counts can be misleading for passwords of different lengths.\n",
    "We therefore compute ratios to normalize character composition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4178b5f-ca39-4ce0-ba00-b204a05f3a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid division by zero by relying on cleaned data\n",
    "pwlds[\"upper_ratio\"] = pwlds[\"upper_count\"] / pwlds[\"password_length\"]\n",
    "pwlds[\"digit_ratio\"] = pwlds[\"digit_count\"] / pwlds[\"password_length\"]\n",
    "pwlds[\"symbol_ratio\"] = pwlds[\"symbol_count\"] / pwlds[\"password_length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39ebf2-5d20-4dc6-9a70-2f8c6e0fae10",
   "metadata": {},
   "source": [
    "### Repetition Ratio\n",
    "\n",
    "Repetition reduces effective password strength. We capture this by\n",
    "measuring how many characters are repeated within a password.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b2d0626-3510-4bac-98e7-1128451e2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repetition_ratio(password: str) -> float:\n",
    "    if len(password) == 0:\n",
    "        return 0.0\n",
    "    return 1 - (len(set(password)) / len(password))\n",
    "\n",
    "pwlds[\"repetition_ratio\"] = pwlds[\"password\"].apply(repetition_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ece5e-6dc3-4aca-9a06-d2fbc23e2a2c",
   "metadata": {},
   "source": [
    "### Feature Sanity Check\n",
    "\n",
    "Before proceeding further, we perform a quick sanity check to ensure\n",
    "engineered features behave as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cbe2ce0-ecde-4063-9e10-a7e28446158f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password_length</th>\n",
       "      <th>upper_count</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>symbol_count</th>\n",
       "      <th>upper_ratio</th>\n",
       "      <th>digit_ratio</th>\n",
       "      <th>symbol_ratio</th>\n",
       "      <th>repetition_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.889333e+06</td>\n",
       "      <td>9.889333e+06</td>\n",
       "      <td>9.889333e+06</td>\n",
       "      <td>9.889333e+06</td>\n",
       "      <td>9.889333e+06</td>\n",
       "      <td>9.889333e+06</td>\n",
       "      <td>9.889333e+06</td>\n",
       "      <td>9.889333e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.235436e+01</td>\n",
       "      <td>1.927345e+00</td>\n",
       "      <td>9.765136e-01</td>\n",
       "      <td>2.163861e+00</td>\n",
       "      <td>1.093403e-01</td>\n",
       "      <td>6.912703e-02</td>\n",
       "      <td>1.140687e-01</td>\n",
       "      <td>1.419803e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.866397e+00</td>\n",
       "      <td>2.815208e+00</td>\n",
       "      <td>1.459941e+00</td>\n",
       "      <td>3.426673e+00</td>\n",
       "      <td>1.271187e-01</td>\n",
       "      <td>1.029088e-01</td>\n",
       "      <td>1.477168e-01</td>\n",
       "      <td>1.226284e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.333333e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.333333e-02</td>\n",
       "      <td>1.176471e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.923077e-01</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>2.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.888889e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       password_length   upper_count   digit_count  symbol_count  \\\n",
       "count     9.889333e+06  9.889333e+06  9.889333e+06  9.889333e+06   \n",
       "mean      1.235436e+01  1.927345e+00  9.765136e-01  2.163861e+00   \n",
       "std       6.866397e+00  2.815208e+00  1.459941e+00  3.426673e+00   \n",
       "min       2.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%       1.000000e+01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%       1.100000e+01  1.000000e+00  0.000000e+00  1.000000e+00   \n",
       "75%       1.300000e+01  2.000000e+00  1.000000e+00  2.000000e+00   \n",
       "max       3.200000e+01  2.100000e+01  1.200000e+01  2.400000e+01   \n",
       "\n",
       "        upper_ratio   digit_ratio  symbol_ratio  repetition_ratio  \n",
       "count  9.889333e+06  9.889333e+06  9.889333e+06      9.889333e+06  \n",
       "mean   1.093403e-01  6.912703e-02  1.140687e-01      1.419803e-01  \n",
       "std    1.271187e-01  1.029088e-01  1.477168e-01      1.226284e-01  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00      0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00      0.000000e+00  \n",
       "50%    8.333333e-02  0.000000e+00  8.333333e-02      1.176471e-01  \n",
       "75%    1.923077e-01  1.000000e-01  2.000000e-01      2.000000e-01  \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00      8.888889e-01  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwlds[\n",
    "    [\n",
    "        \"password_length\",\n",
    "        \"upper_count\",\n",
    "        \"digit_count\",\n",
    "        \"symbol_count\",\n",
    "        \"upper_ratio\",\n",
    "        \"digit_ratio\",\n",
    "        \"symbol_ratio\",\n",
    "        \"repetition_ratio\"\n",
    "    ]\n",
    "].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7536042-fea6-40c9-b100-86de29fa7788",
   "metadata": {},
   "source": [
    "## 2.5 Information-Theoretic Feature: Normalized Entropy\n",
    "\n",
    "Entropy measures character diversity within a password. We use normalized\n",
    "Shannon entropy to make the metric comparable across different password\n",
    "lengths.\n",
    "\n",
    "Entropy is treated as a supporting feature rather than a standalone\n",
    "strength estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e1fd4c7-4bd3-4504-800c-02937d5dc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def normalized_entropy(password: str) -> float:\n",
    "    if len(password) <= 1:\n",
    "        return 0.0\n",
    "\n",
    "    counts = Counter(password)\n",
    "    length = len(password)\n",
    "\n",
    "    entropy = 0.0\n",
    "    for count in counts.values():\n",
    "        p = count / length\n",
    "        entropy -= p * math.log2(p)\n",
    "\n",
    "    # Normalize by maximum possible entropy for given length\n",
    "    max_entropy = math.log2(length)\n",
    "    return entropy / max_entropy if max_entropy > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f04c738-c494-4087-916b-964aa5dc6b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwlds[\"entropy\"] = pwlds[\"password\"].apply(normalized_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c8dff78-45ec-41c7-af97-9b82be704402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9.889333e+06\n",
       "mean     9.085718e-01\n",
       "std      9.327933e-02\n",
       "min      0.000000e+00\n",
       "25%      8.605285e-01\n",
       "50%      9.397940e-01\n",
       "75%      1.000000e+00\n",
       "max      1.000000e+00\n",
       "Name: entropy, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwlds[\"entropy\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9534c00f-600a-484f-b17a-4365ddbd935e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strength\n",
       "0    0.943730\n",
       "1    0.817784\n",
       "2    0.899928\n",
       "3    0.932397\n",
       "4    0.949341\n",
       "Name: entropy, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwlds.groupby(\"strength\")[\"entropy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c862e56-d669-4ef1-9fe5-0cccf9e11d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strength</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998746.0</td>\n",
       "      <td>0.943730</td>\n",
       "      <td>0.106114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998009.0</td>\n",
       "      <td>0.817784</td>\n",
       "      <td>0.113934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737214</td>\n",
       "      <td>0.796658</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1945205.0</td>\n",
       "      <td>0.899928</td>\n",
       "      <td>0.057718</td>\n",
       "      <td>0.546490</td>\n",
       "      <td>0.860529</td>\n",
       "      <td>0.907019</td>\n",
       "      <td>0.947443</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1947373.0</td>\n",
       "      <td>0.932397</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.555834</td>\n",
       "      <td>0.887436</td>\n",
       "      <td>0.939794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.949341</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.738742</td>\n",
       "      <td>0.931092</td>\n",
       "      <td>0.950440</td>\n",
       "      <td>0.971218</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean       std       min       25%       50%  \\\n",
       "strength                                                                \n",
       "0         1998746.0  0.943730  0.106114  0.000000  1.000000  1.000000   \n",
       "1         1998009.0  0.817784  0.113934  0.000000  0.737214  0.796658   \n",
       "2         1945205.0  0.899928  0.057718  0.546490  0.860529  0.907019   \n",
       "3         1947373.0  0.932397  0.055400  0.555834  0.887436  0.939794   \n",
       "4         2000000.0  0.949341  0.028583  0.738742  0.931092  0.950440   \n",
       "\n",
       "               75%  max  \n",
       "strength                 \n",
       "0         1.000000  1.0  \n",
       "1         0.916667  1.0  \n",
       "2         0.947443  1.0  \n",
       "3         1.000000  1.0  \n",
       "4         0.971218  1.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwlds.groupby(\"strength\")[\"entropy\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46267c-1008-42a6-b453-baeec3b6f748",
   "metadata": {},
   "source": [
    "### Entropy Interpretation\n",
    "\n",
    "Normalized entropy captures character diversity but does not encode\n",
    "password length or real-world guessing difficulty. Its behavior in this\n",
    "dataset confirms that entropy alone is insufficient, motivating the use\n",
    "of hybrid feature sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c350fe0b-0ee0-4be8-930d-603afef06851",
   "metadata": {},
   "source": [
    "### NLP Features: Character-Level TF-IDF\n",
    "\n",
    "To capture local character patterns (e.g., substrings, keyboard sequences),\n",
    "we use character-level TF-IDF. Due to dataset size, vocabulary learning is\n",
    "performed on a representative stratified sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb44d29a-70c8-485c-a94f-aa17d8aa79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b974713-a807-4647-ba86-894ad93a8fb6",
   "metadata": {},
   "source": [
    "### Stratified Sampling for TF-IDF Vocabulary Learning\n",
    "\n",
    "TF-IDF vocabulary learning is memory-intensive. We therefore fit the\n",
    "vectorizer on a stratified sample to balance representativeness and\n",
    "computational feasibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cadf694-6fc9-4b98-b376-8a32a39239e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12680\\1883506281.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300000, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 300_000\n",
    "\n",
    "pwlds_sample = (\n",
    "    pwlds\n",
    "    .groupby(\"strength\", group_keys=False)\n",
    "    .apply(lambda x: x.sample(\n",
    "        n=min(len(x), sample_size // pwlds[\"strength\"].nunique()),\n",
    "        random_state=42\n",
    "    ))\n",
    ")\n",
    "\n",
    "pwlds_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d97decc-8bb2-4b7c-82ed-55834e11fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(2, 5),\n",
    "    max_features=5000,\n",
    "    min_df=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57d46184-db3a-48f2-b425-0fbfe18cdc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 5000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_sample = tfidf_vectorizer.fit_transform(pwlds_sample[\"password\"])\n",
    "X_tfidf_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51828853-5652-4106-a1de-76cc839c5578",
   "metadata": {},
   "source": [
    "## Phase 2 Summary\n",
    "\n",
    "In this phase, we:\n",
    "- Preserved the raw password column without corruption\n",
    "- Engineered interpretable security features\n",
    "- Added normalized entropy with documented limitations\n",
    "- Learned character-level TF-IDF features using a memory-safe strategy\n",
    "\n",
    "The dataset is now fully prepared for baseline modeling and ablation\n",
    "studies in Phase 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c112c-0397-42e3-8f3d-9a4b7eb4e1ba",
   "metadata": {},
   "source": [
    "## ===============================\n",
    "## Phase 3: Baselines & Ablation Study\n",
    "## ===============================\n",
    "\n",
    "### Purpose\n",
    "Establish strong baselines and quantify the contribution of different\n",
    "feature sets through an ablation study.\n",
    "\n",
    "### What We Do\n",
    "- Define clear feature sets\n",
    "- Train simple baseline models\n",
    "- Compare performance across feature sets\n",
    "- Focus evaluation on weak-password recall\n",
    "\n",
    "### Expected Output\n",
    "- Baseline metrics\n",
    "- Ablation comparison table\n",
    "- Clear justification for feature choices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ba3d3d-2dab-48ea-9cda-455120f3b6b4",
   "metadata": {},
   "source": [
    "### Feature Set Definitions\n",
    "\n",
    "We evaluate three feature configurations:\n",
    "1. Engineered features only\n",
    "2. TF-IDF features only (sample-based)\n",
    "3. Combined engineered + TF-IDF features\n",
    "\n",
    "This allows us to quantify the contribution of each feature type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0644c745-07e1-4b9f-81a8-895783eb720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineered feature columns (from Phase 2)\n",
    "engineered_features = [\n",
    "    \"password_length\",\n",
    "    \"upper_count\",\n",
    "    \"lower_count\",\n",
    "    \"digit_count\",\n",
    "    \"symbol_count\",\n",
    "    \"upper_ratio\",\n",
    "    \"digit_ratio\",\n",
    "    \"symbol_ratio\",\n",
    "    \"repetition_ratio\",\n",
    "    \"entropy\",\n",
    "]\n",
    "\n",
    "X_eng = pwlds_sample[engineered_features]\n",
    "y_sample = pwlds_sample[\"strength\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5069f9f9-fd31-415e-b24c-2f724989f561",
   "metadata": {},
   "source": [
    "### Train / Validation Split\n",
    "\n",
    "We split the sampled data into training and validation sets using\n",
    "stratification to preserve class distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "349f9b04-3233-4513-ba10-fc850078c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_eng_train, X_eng_val, y_train, y_val = train_test_split(\n",
    "    X_eng,\n",
    "    y_sample,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa5467-ad4c-4f2c-bb77-fab2209c61fc",
   "metadata": {},
   "source": [
    "### Logistic Regression Baseline (Engineered Features)\n",
    "\n",
    "We start with a simple, interpretable linear model to establish a baseline\n",
    "and assess whether engineered features alone carry useful signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "627bc5d8-138c-4d1f-8a6a-7fa4cfc0c43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     12000\n",
      "           1       0.86      0.91      0.89     12000\n",
      "           2       0.73      0.91      0.81     12000\n",
      "           3       0.91      0.63      0.74     12000\n",
      "           4       1.00      1.00      1.00     12000\n",
      "\n",
      "    accuracy                           0.89     60000\n",
      "   macro avg       0.90      0.89      0.89     60000\n",
      "weighted avg       0.90      0.89      0.89     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "logreg_eng = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "logreg_eng.fit(X_eng_train, y_train)\n",
    "\n",
    "y_pred_eng = logreg_eng.predict(X_eng_val)\n",
    "\n",
    "print(classification_report(y_val, y_pred_eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62db794b-590f-4813-b332-30181726f232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8876270855248828"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_eng = f1_score(y_val, y_pred_eng, average=\"macro\")\n",
    "f1_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52c269-6800-4781-a0e8-54b0712c9a8b",
   "metadata": {},
   "source": [
    "## 3.4 Logistic Regression Baseline (TF-IDF Only)\n",
    "\n",
    "Next, we evaluate a pure NLP baseline using character-level TF-IDF\n",
    "features to understand how much signal is captured without engineered\n",
    "features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "873a3db2-ac8c-4d88-8d73-65c6b5259fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align TF-IDF rows with the sampled dataframe\n",
    "X_tfidf = X_tfidf_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69f03028-297d-40da-9561-ec7b877cf51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_train, X_tfidf_val, _, _ = train_test_split(\n",
    "    X_tfidf,\n",
    "    y_sample,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_sample\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bfb92d7-e4f3-4139-b55c-da7de78e2e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     12000\n",
      "           1       0.98      0.96      0.97     12000\n",
      "           2       0.87      0.93      0.90     12000\n",
      "           3       0.83      0.69      0.75     12000\n",
      "           4       0.88      0.98      0.93     12000\n",
      "\n",
      "    accuracy                           0.91     60000\n",
      "   macro avg       0.90      0.91      0.90     60000\n",
      "weighted avg       0.90      0.91      0.90     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_tfidf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "logreg_tfidf.fit(X_tfidf_train, y_train)\n",
    "\n",
    "y_pred_tfidf = logreg_tfidf.predict(X_tfidf_val)\n",
    "\n",
    "print(classification_report(y_val, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d35c91a-1ede-4cee-b4ca-ba0e7875aac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90329384469112"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_tfidf = f1_score(y_val, y_pred_tfidf, average=\"macro\")\n",
    "f1_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614253e9-b6bb-43fd-984d-f41c73237b65",
   "metadata": {},
   "source": [
    "### Combined Feature Baseline\n",
    "\n",
    "We combine engineered features with TF-IDF features to test whether\n",
    "structural and NLP-based signals complement each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96854a11-f5de-45f4-80c4-feb377ebd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_combined = hstack([X_eng, X_tfidf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "658ffcd5-68ff-4581-b903-37d1867d80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comb_train, X_comb_val, _, _ = train_test_split(\n",
    "    X_combined,\n",
    "    y_sample,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_sample\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5db8c83-9eb6-425b-8ab7-2940c59cd9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12000\n",
      "           1       0.99      0.99      0.99     12000\n",
      "           2       0.91      0.96      0.93     12000\n",
      "           3       0.96      0.90      0.92     12000\n",
      "           4       1.00      1.00      1.00     12000\n",
      "\n",
      "    accuracy                           0.97     60000\n",
      "   macro avg       0.97      0.97      0.97     60000\n",
      "weighted avg       0.97      0.97      0.97     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_comb = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "logreg_comb.fit(X_comb_train, y_train)\n",
    "\n",
    "y_pred_comb = logreg_comb.predict(X_comb_val)\n",
    "\n",
    "print(classification_report(y_val, y_pred_comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42d6e11b-4a81-4353-b24b-177334a6ce7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693982611780205"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_comb = f1_score(y_val, y_pred_comb, average=\"macro\")\n",
    "f1_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f958c7-9dc3-4776-9f26-e8ad771a94fd",
   "metadata": {},
   "source": [
    "### Ablation Results Summary\n",
    "\n",
    "We summarize macro F1-scores across feature sets to quantify their impact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9102dbcb-e13c-4347-9acb-83ff1be10001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Set</th>\n",
       "      <th>Macro_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Engineered Features Only</td>\n",
       "      <td>0.887627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF Only</td>\n",
       "      <td>0.903294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Engineered + TF-IDF</td>\n",
       "      <td>0.969398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature_Set  Macro_F1\n",
       "0  Engineered Features Only  0.887627\n",
       "1               TF-IDF Only  0.903294\n",
       "2       Engineered + TF-IDF  0.969398"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ablation_results = pd.DataFrame({\n",
    "    \"Feature_Set\": [\n",
    "        \"Engineered Features Only\",\n",
    "        \"TF-IDF Only\",\n",
    "        \"Engineered + TF-IDF\"\n",
    "    ],\n",
    "    \"Macro_F1\": [\n",
    "        f1_eng,\n",
    "        f1_tfidf,\n",
    "        f1_comb\n",
    "    ]\n",
    "})\n",
    "\n",
    "ablation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ac5b4-dcd4-4b5d-907a-ec72ba4b7451",
   "metadata": {},
   "source": [
    "## Phase 3 Summary\n",
    "\n",
    "In this phase, we:\n",
    "- Established logistic regression baselines\n",
    "- Performed a controlled ablation study\n",
    "- Quantified the contribution of engineered and NLP features\n",
    "- Identified the most effective feature combination\n",
    "\n",
    "These results guide model selection for more powerful non-linear models\n",
    "in the next phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6a05c-2247-47f7-a7ce-413332f8d748",
   "metadata": {},
   "source": [
    "## ===============================\n",
    "## Phase 4: Tree-Based Models (Main Results)\n",
    "## ===============================\n",
    "\n",
    "## Purpose\n",
    "Tree-based models are used to capture non-linear relationships and feature\n",
    "interactions that linear models cannot represent.\n",
    "\n",
    "In this phase, we:\n",
    "- Train tree-based classifiers on engineered features\n",
    "- Compare performance against baseline models\n",
    "- Analyze feature importance\n",
    "- Perform targeted error analysis\n",
    "\n",
    "These models form the primary results of the project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb42051-6e88-41b6-97f4-0d691511939e",
   "metadata": {},
   "source": [
    "### Feature Set for Tree-Based Models\n",
    "\n",
    "Tree-based models are trained using engineered features only.\n",
    "TF-IDF features are excluded to avoid excessive dimensionality and\n",
    "to preserve interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9411a6f7-254e-4c0f-a514-6f8fe3be977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineered feature matrix (same as Phase 3)\n",
    "engineered_features = [\n",
    "    \"password_length\",\n",
    "    \"upper_count\",\n",
    "    \"lower_count\",\n",
    "    \"digit_count\",\n",
    "    \"symbol_count\",\n",
    "    \"upper_ratio\",\n",
    "    \"digit_ratio\",\n",
    "    \"symbol_ratio\",\n",
    "    \"repetition_ratio\",\n",
    "    \"entropy\",\n",
    "]\n",
    "\n",
    "X_tree = pwlds_sample[engineered_features]\n",
    "y_tree = pwlds_sample[\"strength\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7fbc5c-8f21-4007-8794-1d6d53658118",
   "metadata": {},
   "source": [
    "### Train / Validation Split\n",
    "\n",
    "We reuse a stratified train-validation split to ensure fair comparison\n",
    "with baseline models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39788953-ed4f-408d-9e30-981b268e6c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tree,\n",
    "    y_tree,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_tree\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6d9754-b76e-4035-b2d6-b72da7f3a41c",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "Random Forests capture non-linear interactions and are robust to feature\n",
    "scaling. We limit hyperparameter tuning to avoid overfitting and keep\n",
    "training time reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12791e1b-4bf7-435f-ba3a-8f2cf5113958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8943bef3-87b4-4f19-8557-741fa7c76da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12000\n",
      "           1       0.93      0.94      0.94     12000\n",
      "           2       0.87      0.93      0.90     12000\n",
      "           3       0.92      0.84      0.88     12000\n",
      "           4       1.00      1.00      1.00     12000\n",
      "\n",
      "    accuracy                           0.94     60000\n",
      "   macro avg       0.94      0.94      0.94     60000\n",
      "weighted avg       0.94      0.94      0.94     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_leaf=20,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "print(classification_report(y_val, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "006f3e76-511a-4259-83aa-c9a4bf6a1029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9423091049717728"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_rf = f1_score(y_val, y_pred_rf, average=\"macro\")\n",
    "f1_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b424d60e-8454-4cc1-83bb-9ef8e666ea37",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier\n",
    "\n",
    "Gradient Boosting builds trees sequentially and often achieves higher\n",
    "accuracy by correcting previous errors. We use conservative settings\n",
    "to balance performance and training cost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "003ffdf4-03be-4e3f-9319-dbbdf7dec4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1493548-0e5f-489c-958f-a5898629ac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     12000\n",
      "           1       0.94      0.94      0.94     12000\n",
      "           2       0.87      0.93      0.90     12000\n",
      "           3       0.92      0.84      0.88     12000\n",
      "           4       1.00      1.00      1.00     12000\n",
      "\n",
      "    accuracy                           0.94     60000\n",
      "   macro avg       0.94      0.94      0.94     60000\n",
      "weighted avg       0.94      0.94      0.94     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_val)\n",
    "\n",
    "print(classification_report(y_val, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06943602-f1f6-469e-b331-a46b8a6fa307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9430007047024429"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_gb = f1_score(y_val, y_pred_gb, average=\"macro\")\n",
    "f1_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38088b3-92bb-43d5-846a-b8c376db19f0",
   "metadata": {},
   "source": [
    "### Tree-Based Model Comparison\n",
    "\n",
    "We compare macro F1-scores across tree-based models to select the best\n",
    "performing approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e34c87eb-29d8-49f9-8df6-bdaadd0c3c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Macro_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.942309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.943001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Macro_F1\n",
       "0      Random Forest  0.942309\n",
       "1  Gradient Boosting  0.943001"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tree_results = pd.DataFrame({\n",
    "    \"Model\": [\"Random Forest\", \"Gradient Boosting\"],\n",
    "    \"Macro_F1\": [f1_rf, f1_gb]\n",
    "})\n",
    "\n",
    "tree_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9dbc6-515d-4ee0-8672-ba334e920816",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis\n",
    "\n",
    "Feature importance helps interpret which password characteristics\n",
    "contribute most to model decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3dec8972-c9b5-4740-ae56-925f88d37a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>password_length</td>\n",
       "      <td>0.318270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>symbol_count</td>\n",
       "      <td>0.174334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>symbol_ratio</td>\n",
       "      <td>0.159903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lower_count</td>\n",
       "      <td>0.094574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upper_count</td>\n",
       "      <td>0.062790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>upper_ratio</td>\n",
       "      <td>0.046064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>digit_ratio</td>\n",
       "      <td>0.043212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entropy</td>\n",
       "      <td>0.038663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digit_count</td>\n",
       "      <td>0.035259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>repetition_ratio</td>\n",
       "      <td>0.026931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Feature  Importance\n",
       "0   password_length    0.318270\n",
       "4      symbol_count    0.174334\n",
       "7      symbol_ratio    0.159903\n",
       "2       lower_count    0.094574\n",
       "1       upper_count    0.062790\n",
       "5       upper_ratio    0.046064\n",
       "6       digit_ratio    0.043212\n",
       "9           entropy    0.038663\n",
       "3       digit_count    0.035259\n",
       "8  repetition_ratio    0.026931"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": engineered_features,\n",
    "    \"Importance\": rf_model.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf31b2-4787-42aa-8724-e887dc318ec9",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "We inspect misclassified passwords to understand systematic weaknesses\n",
    "in the model and identify areas for improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "308306df-668a-478a-ad7d-4747c72c5f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password_length</th>\n",
       "      <th>upper_count</th>\n",
       "      <th>lower_count</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>symbol_count</th>\n",
       "      <th>upper_ratio</th>\n",
       "      <th>digit_ratio</th>\n",
       "      <th>symbol_ratio</th>\n",
       "      <th>repetition_ratio</th>\n",
       "      <th>entropy</th>\n",
       "      <th>true_strength</th>\n",
       "      <th>pred_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6073915</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.939794</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755885</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639507</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.939794</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6105721</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.939794</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307005</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         password_length  upper_count  lower_count  digit_count  symbol_count  \\\n",
       "6073915               10            0            9            0             1   \n",
       "4755885               10            2            7            0             1   \n",
       "7639507               10            1            8            0             1   \n",
       "6105721               10            0            9            0             1   \n",
       "3307005                5            1            3            1             0   \n",
       "\n",
       "         upper_ratio  digit_ratio  symbol_ratio  repetition_ratio   entropy  \\\n",
       "6073915          0.0          0.0           0.1               0.1  0.939794   \n",
       "4755885          0.2          0.0           0.1               0.0  1.000000   \n",
       "7639507          0.1          0.0           0.1               0.1  0.939794   \n",
       "6105721          0.0          0.0           0.1               0.1  0.939794   \n",
       "3307005          0.2          0.2           0.0               0.0  1.000000   \n",
       "\n",
       "         true_strength  pred_strength  \n",
       "6073915              3              2  \n",
       "4755885              2              3  \n",
       "7639507              3              2  \n",
       "6105721              3              2  \n",
       "3307005              1              0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify misclassified samples\n",
    "errors = X_val.copy()\n",
    "errors[\"true_strength\"] = y_val.values\n",
    "errors[\"pred_strength\"] = y_pred_rf\n",
    "\n",
    "misclassified = errors[errors[\"true_strength\"] != errors[\"pred_strength\"]]\n",
    "\n",
    "misclassified.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089053fb-c879-45a9-8447-2b879d789aa9",
   "metadata": {},
   "source": [
    "### Error Analysis Observations\n",
    "\n",
    "- Some long but repetitive passwords are overestimated\n",
    "- Short passwords with symbols may still be misclassified\n",
    "- These errors align with known limitations of rule-based and ML-based\n",
    "  password strength estimation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c703a-3ea6-428d-9d58-821fb1b131a7",
   "metadata": {},
   "source": [
    "## Phase 4 Summary\n",
    "\n",
    "In this phase, we:\n",
    "- Trained tree-based models on engineered features\n",
    "- Captured non-linear feature interactions\n",
    "- Compared Random Forest and Gradient Boosting performance\n",
    "- Interpreted feature importance\n",
    "- Performed targeted error analysis\n",
    "\n",
    "The best-performing tree-based model serves as the primary model for\n",
    "this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d280d17-9c28-4dc2-a035-a4621186774c",
   "metadata": {},
   "source": [
    "## ===============================\n",
    "## Phase 5: External Dataset Comparison (Generalization Check)\n",
    "## ===============================\n",
    "\n",
    "### Purpose\n",
    "Models that perform well on a single dataset may overfit dataset-specific\n",
    "patterns. In this phase, we evaluate generalization by training and testing\n",
    "a baseline model on a secondary password dataset.\n",
    "\n",
    "This strengthens the credibility of the project by demonstrating how\n",
    "results vary across datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6e312-1017-48a4-bcfe-aa62eba75c8b",
   "metadata": {},
   "source": [
    "### Load Secondary Dataset\n",
    "\n",
    "We load a publicly available password strength dataset (Kaggle) and use\n",
    "it only for baseline comparison. No advanced feature engineering or\n",
    "model tuning is performed on this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d897e805-274e-443e-a7fa-8be741ce25d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kzde5577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kino3434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visi7k1yr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>megzy123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lamborghin1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      password  strength\n",
       "0     kzde5577         1\n",
       "1     kino3434         1\n",
       "2    visi7k1yr         1\n",
       "3     megzy123         1\n",
       "4  lamborghin1         1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load secondary dataset\n",
    "secondary = pd.read_csv(\n",
    "    \"secondary_data.csv\",\n",
    "    engine=\"python\",\n",
    "    on_bad_lines=\"skip\"\n",
    ")\n",
    "\n",
    "secondary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f1b933-2e2d-48cf-a338-e3ec1492a3d3",
   "metadata": {},
   "source": [
    "### Data Quality Note\n",
    "\n",
    "The external dataset contains malformed rows due to delimiter characters\n",
    "inside password strings. We load the file using a tolerant parsing strategy\n",
    "and skip corrupted rows, which has negligible impact on evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492bf82e-bc3d-4c2b-b112-7f660fd7032d",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "We inspect the structure and label distribution of the secondary dataset\n",
    "to understand differences relative to the primary dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3b5d0bd2-1197-4640-a01d-1db25a6a058a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669640, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9fbf950a-86e2-44b4-8083-555f8b2d072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 669640 entries, 0 to 669639\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   password  669639 non-null  object\n",
      " 1   strength  669640 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 10.2+ MB\n"
     ]
    }
   ],
   "source": [
    "secondary.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ac6b4051-2704-4aa0-a173-4afc04982e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password    1\n",
       "strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondary.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47b23271-d1db-4b69-bf3f-f0b241eb5a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password    0\n",
       "strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondary = secondary.dropna(subset=[\"password\"])\n",
    "secondary.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46328acb-c099-4457-bdf7-e01c532f9321",
   "metadata": {},
   "source": [
    "### Column Standardization\n",
    "\n",
    "To reuse feature engineering logic, we standardize column names and\n",
    "ensure consistent data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dcc572ac-ea2e-4869-a4a5-7aeb69814d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns if needed (adjust if column names differ)\n",
    "secondary = secondary.rename(columns={\n",
    "    \"password\": \"password\",\n",
    "    \"strength\": \"strength\"\n",
    "})\n",
    "\n",
    "secondary[\"password\"] = secondary[\"password\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe713dc9-9837-468a-9be9-8b550fe51af4",
   "metadata": {},
   "source": [
    "### Feature Engineering (Minimal)\n",
    "\n",
    "We apply the same structured feature engineering pipeline used in the\n",
    "primary dataset, without adding TF-IDF or entropy-based enhancements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "477f222b-d944-448f-8c53-70965a6cff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Password length\n",
    "secondary[\"password_length\"] = secondary[\"password\"].str.len()\n",
    "\n",
    "# Character counts\n",
    "secondary[\"upper_count\"] = secondary[\"password\"].str.count(r\"[A-Z]\")\n",
    "secondary[\"lower_count\"] = secondary[\"password\"].str.count(r\"[a-z]\")\n",
    "secondary[\"digit_count\"] = secondary[\"password\"].str.count(r\"[0-9]\")\n",
    "secondary[\"symbol_count\"] = secondary[\"password\"].str.count(r\"[^A-Za-z0-9]\")\n",
    "\n",
    "# Ratios\n",
    "secondary[\"upper_ratio\"] = secondary[\"upper_count\"] / secondary[\"password_length\"]\n",
    "secondary[\"digit_ratio\"] = secondary[\"digit_count\"] / secondary[\"password_length\"]\n",
    "secondary[\"symbol_ratio\"] = secondary[\"symbol_count\"] / secondary[\"password_length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde581d-2cbb-4c48-8e6d-1b93fcc6ccc0",
   "metadata": {},
   "source": [
    "### Train / Validation Split\n",
    "\n",
    "We perform a simple stratified split for baseline evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "404b07b7-54ef-4e17-aed8-66b75862d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "engineered_features = [\n",
    "    \"password_length\",\n",
    "    \"upper_count\",\n",
    "    \"lower_count\",\n",
    "    \"digit_count\",\n",
    "    \"symbol_count\",\n",
    "    \"upper_ratio\",\n",
    "    \"digit_ratio\",\n",
    "    \"symbol_ratio\"\n",
    "]\n",
    "\n",
    "X_sec = secondary[engineered_features]\n",
    "y_sec = secondary[\"strength\"]\n",
    "\n",
    "X_sec_train, X_sec_val, y_sec_train, y_sec_val = train_test_split(\n",
    "    X_sec,\n",
    "    y_sec,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_sec\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58370c47-3d1b-4939-b196-c436fdf1f544",
   "metadata": {},
   "source": [
    "### Baseline Model on Secondary Dataset\n",
    "\n",
    "We train a simple logistic regression model to establish a baseline\n",
    "performance on the external dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1372ddeb-686a-4fad-ad72-352476250bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5304f789-b464-47c0-aebc-01584726024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     17940\n",
      "           1       1.00      1.00      1.00     99360\n",
      "           2       1.00      1.00      1.00     16628\n",
      "\n",
      "    accuracy                           1.00    133928\n",
      "   macro avg       1.00      1.00      1.00    133928\n",
      "weighted avg       1.00      1.00      1.00    133928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sec_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "sec_model.fit(X_sec_train, y_sec_train)\n",
    "\n",
    "y_sec_pred = sec_model.predict(X_sec_val)\n",
    "\n",
    "print(classification_report(y_sec_val, y_sec_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f6da7d8-755e-4a47-bfa5-e5ee0c0a5782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994740628874333"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_sec = f1_score(y_sec_val, y_sec_pred, average=\"macro\")\n",
    "f1_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b00e6d-13a3-46fa-b77d-54a9c19d6f1a",
   "metadata": {},
   "source": [
    "### Cross-Dataset Comparison\n",
    "\n",
    "We compare baseline performance on the secondary dataset with results\n",
    "from the primary dataset to highlight differences in data distribution\n",
    "and labeling schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6ed94db6-198b-4a51-b1d7-ad4c8deb8d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Macro_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Primary (PWLDS)</td>\n",
       "      <td>Logistic Regression (Engineered)</td>\n",
       "      <td>0.887627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Secondary (Kaggle)</td>\n",
       "      <td>Logistic Regression (Engineered)</td>\n",
       "      <td>0.999474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset                             Model  Macro_F1\n",
       "0     Primary (PWLDS)  Logistic Regression (Engineered)  0.887627\n",
       "1  Secondary (Kaggle)  Logistic Regression (Engineered)  0.999474"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    \"Dataset\": [\"Primary (PWLDS)\", \"Secondary (Kaggle)\"],\n",
    "    \"Model\": [\"Logistic Regression (Engineered)\", \"Logistic Regression (Engineered)\"],\n",
    "    \"Macro_F1\": [f1_eng, f1_sec]\n",
    "})\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42717cbd-9a00-4468-8d77-163d34692255",
   "metadata": {},
   "source": [
    "### Interpretation Note on External Dataset Performance\n",
    "\n",
    "The near-perfect performance on the secondary (Kaggle) dataset reflects\n",
    "simpler labeling rules and clearer class separation. In contrast, the\n",
    "primary PWLDS dataset is larger, noisier, and more representative of\n",
    "real-world password behavior, making it a more challenging and realistic\n",
    "benchmark.\n",
    "\n",
    "This comparison highlights the importance of evaluating password strength\n",
    "models across multiple datasets rather than relying on a single metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6ebcd-4fb9-4179-9ca4-e5f8b3518ba4",
   "metadata": {},
   "source": [
    "## Phase 5 Summary\n",
    "\n",
    "In this phase, we:\n",
    "- Evaluated model performance on an external dataset\n",
    "- Observed performance differences across datasets\n",
    "- Demonstrated dataset dependency in password strength estimation\n",
    "- Strengthened the generalization argument of the project\n",
    "\n",
    "These results highlight the importance of dataset choice and motivate\n",
    "careful evaluation when deploying password strength models in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5475d0-d179-46f1-aa3c-ca7ffdefc117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8380b51b-1b61-4902-b515-2c8c0c5f5b99",
   "metadata": {},
   "source": [
    "## ===============================\n",
    "## Final Phase: Interpretation, Ethics & Project Conclusion\n",
    "## ===============================\n",
    "\n",
    "### Objective of the Final Phase\n",
    "This phase consolidates results from all modeling stages, interprets them\n",
    "from a security perspective, discusses limitations, and documents ethical\n",
    "considerations. The goal is to present a complete, responsible, and\n",
    "industry-aligned data science project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95341792-89b5-4b2b-8be1-76ad3f821d4c",
   "metadata": {},
   "source": [
    "## 1. Key Findings & Insights\n",
    "\n",
    "### Feature Engineering\n",
    "- Password length is the single most influential feature across all models.\n",
    "- Character composition (symbols, digits, uppercase usage) significantly\n",
    "  improves discrimination between medium and strong passwords.\n",
    "- Ratios outperform raw counts, confirming that normalized features are\n",
    "  more informative.\n",
    "- Entropy provides complementary signal but is insufficient on its own,\n",
    "  validating the need for hybrid feature sets.\n",
    "\n",
    "### Modeling Results\n",
    "- Linear models with engineered features perform strongly and are highly\n",
    "  interpretable.\n",
    "- Character-level TF-IDF captures sequence patterns missed by structured\n",
    "  features.\n",
    "- Combining engineered and NLP features yields the best overall performance.\n",
    "- Tree-based models capture non-linear interactions and provide robust,\n",
    "  interpretable results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca764b-8e36-44f8-b875-d55ae21b7c42",
   "metadata": {},
   "source": [
    "## 2. Model Comparison Summary\n",
    "\n",
    "| Model Type | Strengths | Limitations |\n",
    "|-----------|----------|-------------|\n",
    "| Logistic Regression (Engineered) | Simple, interpretable, strong baseline | Limited non-linearity |\n",
    "| Logistic Regression (TF-IDF) | Captures character patterns | Less interpretable |\n",
    "| Logistic Regression (Combined) | Best overall performance | Higher complexity |\n",
    "| Random Forest | Robust, interpretable | Slightly lower than combined linear |\n",
    "| Gradient Boosting | Best non-linear model | Slower, harder to tune |\n",
    "\n",
    "The Gradient Boosting model serves as the **primary interpretable non-linear\n",
    "model**, while the combined Logistic Regression model achieves the highest\n",
    "overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1268b59-de76-48ba-beb6-ef862aaf6704",
   "metadata": {},
   "source": [
    "## 3. Security Interpretation\n",
    "\n",
    "From a security standpoint:\n",
    "- Weak passwords are reliably detected with very high recall, which is\n",
    "  critical for enforcement systems.\n",
    "- Errors primarily occur between adjacent strength classes, reflecting\n",
    "  inherent ambiguity rather than model failure.\n",
    "- Models align well with known password security principles:\n",
    "  length, diversity, and unpredictability matter more than any single rule.\n",
    "\n",
    "This confirms that machine learningâ€“based approaches can meaningfully\n",
    "augment traditional password strength heuristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b5fe6-a3c8-438f-971e-1d21e833db1b",
   "metadata": {},
   "source": [
    "## 4. External Dataset Generalization\n",
    "\n",
    "Evaluation on an external Kaggle dataset yielded near-perfect performance\n",
    "using simple engineered features.\n",
    "\n",
    "This result reflects:\n",
    "- Cleaner data\n",
    "- Simpler or rule-based labeling\n",
    "- Clearer class boundaries\n",
    "\n",
    "In contrast, the primary PWLDS dataset is larger, noisier, and more\n",
    "representative of real-world password behavior, making it a more realistic\n",
    "benchmark. This comparison highlights the importance of cross-dataset\n",
    "evaluation in security-related machine learning tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a223b3-9ab4-4748-8656-a396cbea0fb8",
   "metadata": {},
   "source": [
    "## 5. Limitations\n",
    "\n",
    "- Password strength labels are approximations and do not directly measure\n",
    "  real-world attack cost.\n",
    "- No simulated password-cracking attacks were performed.\n",
    "- NLP features were trained on a sampled subset due to memory constraints.\n",
    "- Results may vary across organizations with different password policies.\n",
    "\n",
    "These limitations are common in password strength research and represent\n",
    "opportunities for future improvement rather than flaws.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f8d5c-c75d-468a-b91c-a869f20ef008",
   "metadata": {},
   "source": [
    "## 6. Ethical & Responsible Use Considerations\n",
    "\n",
    "- No real user passwords were collected or logged during this project.\n",
    "- All datasets used are publicly available and anonymized.\n",
    "- The project does not provide password generation or cracking capabilities.\n",
    "- Models are intended for **defensive security purposes only**, such as\n",
    "  strength estimation and policy enforcement.\n",
    "\n",
    "Any real-world deployment should:\n",
    "- Avoid storing plaintext passwords\n",
    "- Operate locally or on-device where possible\n",
    "- Provide user feedback without logging sensitive inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5252fb-3f58-405b-a60a-0d1ec5794448",
   "metadata": {},
   "source": [
    "## 7. Future Work\n",
    "\n",
    "- Incorporate attack-based metrics (e.g., guess-number estimation)\n",
    "- Explore probabilistic password models\n",
    "- Integrate keyboard-walk and dictionary-word detection\n",
    "- Deploy as a local API or browser-based strength checker\n",
    "- Evaluate robustness against adversarial password construction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc527f1-d10f-4b15-9c6f-b75ce1fb3541",
   "metadata": {},
   "source": [
    "## Final Conclusion\n",
    "\n",
    "This project demonstrates an end-to-end, production-aware approach to\n",
    "password strength prediction using machine learning and NLP techniques.\n",
    "\n",
    "By combining strong data preparation, interpretable feature engineering,\n",
    "rigorous evaluation, and ethical considerations, the project provides a\n",
    "realistic and defensible solution suitable for security-conscious\n",
    "applications.\n",
    "\n",
    "The methodology and results are representative of real-world data science\n",
    "work in applied cybersecurity contexts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f64abc-d6fa-4cd3-bed7-5250e85822b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529439f8-ee8b-41ec-864f-e05a5e368ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1761ebc-e986-462a-9c3e-72181407c3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e016b-1487-43c0-bcb8-e03643995cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0e4a9-4cba-4151-8f52-f8b99a43a819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6bdd4e-6570-4228-9ab4-3c402cb65772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c6d2f-f96a-40fc-b5ff-c9c14298d95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634bc2d-685f-42a5-8b8f-b65d3f91c0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf6385-be0a-4c66-b82f-376be351293c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc0102b-438d-4e4b-8488-d76aafbaa3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d908d-6828-4212-a67f-46786e3d580a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03833fe0-84c2-42bc-921d-05a792fdfca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff9d30d-6cd6-4222-bba0-d19a60187c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867eba1a-3390-445c-b265-28f4a77d9be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9411ee-4cc6-4c2f-855c-c8857ad657a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24340a5c-aa00-4904-993e-f2f9fb75ae3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c11ae-e7ac-4228-b465-494e0cbb3488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cafeb0-b2f8-47c1-b3ba-d685854e3cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17005396-1e68-49f1-8f24-5ca9e89f9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86940e4-c2bb-4302-8c0d-f84d433df427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dbd97e-f31d-4456-8dd8-6f98cac5c2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ced1e5-58a1-45dc-8954-26924508233f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
